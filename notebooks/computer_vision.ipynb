{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T09:45:13.908014Z",
     "start_time": "2024-03-27T09:45:10.610623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "FasterRCNN(\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n  (backbone): BackboneWithFPN(\n    (body): IntermediateLayerGetter(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): FrozenBatchNorm2d(256, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(512, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(1024, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(2048, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (fpn): FeaturePyramidNetwork(\n      (inner_blocks): ModuleList(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (layer_blocks): ModuleList(\n        (0-3): 4 x Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (extra_blocks): LastLevelMaxPool()\n    )\n  )\n  (rpn): RegionProposalNetwork(\n    (anchor_generator): AnchorGenerator()\n    (head): RPNHead(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n      )\n      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): RoIHeads(\n    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n    (box_head): TwoMLPHead(\n      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNPredictor(\n      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "model.load_state_dict(torch.load(\"model1.pth\", map_location=torch.device(\"cpu\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 11:45:14.341 python[24356:1001452] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[498  50 941 546]]\n",
      "drawing\n",
      "[[471  13 906 485]]\n",
      "drawing\n",
      "[[573  66 840 367]]\n",
      "drawing\n",
      "[[535  27 849 383]]\n",
      "drawing\n",
      "[[510  35 823 405]]\n",
      "drawing\n",
      "[[628  34 936 382]\n",
      " [373 343 552 557]]\n",
      "drawing\n",
      "drawing\n",
      "[[627  38 935 388]\n",
      " [395 315 583 527]]\n",
      "drawing\n",
      "drawing\n",
      "[[613  36 927 382]\n",
      " [357 341 515 536]]\n",
      "drawing\n",
      "drawing\n",
      "[[608  37 907 383]\n",
      " [342 388 508 584]]\n",
      "drawing\n",
      "drawing\n",
      "[[469  84 781 470]]\n",
      "drawing\n",
      "[[474  94 794 475]]\n",
      "drawing\n",
      "[[473  98 784 476]]\n",
      "drawing\n",
      "[[465  89 786 476]]\n",
      "drawing\n",
      "[[465  94 785 474]]\n",
      "drawing\n",
      "[[467  93 786 478]]\n",
      "drawing\n",
      "[[467  94 783 477]]\n",
      "drawing\n",
      "[[469  95 783 476]]\n",
      "drawing\n",
      "[[465  92 796 492]]\n",
      "drawing\n",
      "[[456  85 804 501]]\n",
      "drawing\n",
      "[[459  95 794 480]]\n",
      "drawing\n",
      "[[467 105 783 476]]\n",
      "drawing\n",
      "[[471  98 777 494]]\n",
      "drawing\n",
      "[[464 102 785 487]]\n",
      "drawing\n",
      "[[ 452   25  793  388]\n",
      " [1155  122 1279  296]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 478    3  892  441]\n",
      " [1173  232 1280  418]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 441   23  846  459]\n",
      " [ 932  258 1083  447]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 444   21  844  464]\n",
      " [ 948  243 1093  431]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 448   11  852  443]\n",
      " [ 958  254 1110  447]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 433   14  845  461]\n",
      " [ 932  254 1090  451]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 436   16  842  461]\n",
      " [ 935  266 1078  454]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 425    4  827  468]\n",
      " [ 929  252 1087  455]]\n",
      "drawing\n",
      "drawing\n",
      "[[439  10 839 462]]\n",
      "drawing\n",
      "[[402  14 825 497]]\n",
      "drawing\n",
      "[[393   9 801 468]]\n",
      "drawing\n",
      "[[386   0 822 442]]\n",
      "drawing\n",
      "[[ 399   15  838  456]\n",
      " [1057  166 1223  384]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 404   20  840  468]\n",
      " [1034  236 1187  439]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 412    7  842  481]\n",
      " [1053  230 1205  428]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 400   19  838  480]\n",
      " [1016  222 1183  427]]\n",
      "drawing\n",
      "drawing\n",
      "[[ 403   14  839  484]\n",
      " [1007  221 1171  422]]\n",
      "drawing\n",
      "drawing\n",
      "[[609  64 858 351]]\n",
      "drawing\n",
      "[[470   6 901 491]]\n",
      "drawing\n",
      "[[466   9 895 489]]\n",
      "drawing\n",
      "[[451   9 891 477]]\n",
      "drawing\n",
      "[[438  13 886 476]]\n",
      "drawing\n",
      "[[435  13 865 485]]\n",
      "drawing\n",
      "[[432  14 853 460]]\n",
      "drawing\n",
      "[[437  12 861 489]]\n",
      "drawing\n",
      "[[449  23 877 518]]\n",
      "drawing\n",
      "[[459  29 876 511]]\n",
      "drawing\n",
      "[[575  37 865 382]]\n",
      "drawing\n",
      "[[529   3 943 458]]\n",
      "drawing\n",
      "[[301  24 737 525]]\n",
      "drawing\n",
      "[[355   0 816 493]]\n",
      "drawing\n",
      "[[538   0 988 432]]\n",
      "drawing\n",
      "[[497  12 849 398]]\n",
      "drawing\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[[427  45 709 385]]\n",
      "drawing\n",
      "[]\n",
      "[[486   0 848 302]]\n",
      "drawing\n",
      "[[466 184 888 676]]\n",
      "drawing\n",
      "[[428 193 857 671]]\n",
      "drawing\n",
      "[[447 204 862 625]]\n",
      "drawing\n",
      "[[427 195 860 624]]\n",
      "drawing\n",
      "[[427 171 832 660]]\n",
      "drawing\n",
      "[[444 194 858 664]]\n",
      "drawing\n",
      "[[415 201 824 687]]\n",
      "drawing\n",
      "[[423 198 816 677]]\n",
      "drawing\n",
      "[[428 205 824 670]]\n",
      "drawing\n",
      "[[433 190 872 713]]\n",
      "drawing\n",
      "[[425 211 816 700]]\n",
      "drawing\n",
      "[[413 210 815 706]]\n",
      "drawing\n",
      "[[393 219 820 687]]\n",
      "drawing\n",
      "[[408 213 805 704]]\n",
      "drawing\n",
      "[[406 210 803 703]]\n",
      "drawing\n",
      "[[408 203 793 699]]\n",
      "drawing\n",
      "[[410 208 810 691]]\n",
      "drawing\n",
      "[[428 202 878 682]]\n",
      "drawing\n",
      "[[446 204 873 681]]\n",
      "drawing\n",
      "[[443 221 869 671]]\n",
      "drawing\n",
      "[[472 223 887 684]]\n",
      "drawing\n",
      "[[453 231 861 675]]\n",
      "drawing\n",
      "[[445 207 835 662]]\n",
      "drawing\n",
      "[[437 214 851 687]]\n",
      "drawing\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "    orig_frame = frame.copy()\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    image /= 255.0\n",
    "    image = np.transpose(image, (2, 0, 1)).astype(float)\n",
    "    image = torch.tensor(image, dtype=torch.float)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "\n",
    "    outputs = [{k: v.to('cpu') for k, v in t.items()} for t in outputs]\n",
    "    if len(outputs[0]['boxes']) != 0:\n",
    "        boxes = outputs[0]['boxes'].data.numpy()\n",
    "        scores = outputs[0]['scores'].data.numpy()\n",
    "        boxes = boxes[scores >= 0.8].astype(np.int32)\n",
    "        draw_boxes = boxes.copy()\n",
    "        print(draw_boxes)\n",
    "\n",
    "        for _, box in enumerate(draw_boxes):\n",
    "            cv2.rectangle(\n",
    "                orig_frame,\n",
    "                (int(box[0]), int(box[1])),\n",
    "                (int(box[2]), int(box[3])),\n",
    "                (0, 0, 255),  # Red color\n",
    "                2\n",
    "            )\n",
    "            print(\"drawing\")\n",
    "\n",
    "    cv2.imshow('EyeTrack', orig_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-27T09:45:13.914670Z"
    }
   },
   "id": "7caa3445f96d039d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2171e9f4e840438c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
